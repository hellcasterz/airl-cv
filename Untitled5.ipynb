{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Vision Transformer [ViT] on Cifar 10 dataset"
   ],
   "metadata": {
    "id": "tKJmfP9uIunk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# define\n",
    "IMAGE_SIZE = 32\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "PATCH_SIZE = 4\n",
    "HEADS_NUM = 8\n",
    "BLOCK_SIZE = 8\n",
    "EMBED_DIM = 256\n",
    "\n",
    "EPOCHS = 80"
   ],
   "metadata": {
    "id": "YK1dN8jtJuoK",
    "ExecuteTime": {
     "end_time": "2025-10-04T12:06:42.576585Z",
     "start_time": "2025-10-04T12:06:42.567380Z"
    }
   },
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4IsZ6XmIIWSO",
    "outputId": "9a247ce6-6058-4306-d15e-145d19ebda7a",
    "ExecuteTime": {
     "end_time": "2025-10-04T12:06:46.240686Z",
     "start_time": "2025-10-04T12:06:44.816797Z"
    }
   },
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as T\n",
    "\n",
    "transform_train = T.Compose([\n",
    "    T.RandomCrop(IMAGE_SIZE, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25),\n",
    "    T.RandomAffine(degrees=25, translate=(0.1, 0.1)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    T.RandomErasing(p=0.5, scale=(0.05, 0.25), ratio=(0.3, 3.3), value=0)\n",
    "])\n",
    "\n",
    "transform_test = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "train_dataset = CIFAR10(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_train)\n",
    "\n",
    "test_dataset = CIFAR10(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_test)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}, Test dataset size: {len(test_dataset)}\")\n",
    "# Train dataset size: 50000, Test dataset size: 10000"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 50000, Test dataset size: 10000\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True)\n",
    "\n",
    "print(f\"Number of training batches: {len(train_dataloader)}\")\n",
    "print(f\"Number of test batches: {len(test_dataloader)}\")\n",
    "#Number of training batches: 391\n",
    "#Number of test batches: 79"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hz_zJ89AIs8w",
    "outputId": "11634d9f-7d5e-45ec-e1b7-c08aa465fdd0",
    "ExecuteTime": {
     "end_time": "2025-10-04T12:16:35.099722Z",
     "start_time": "2025-10-04T12:16:35.061684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 391\n",
      "Number of test batches: 79\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Embedding Layer for Vision Transformer\n",
    "class ViTEmbedding(nn.Module):\n",
    "    def __init__(self, img_size=IMAGE_SIZE, patch_size=PATCH_SIZE, in_channels=3, embed_dim=EMBED_DIM):\n",
    "        super().__init__()\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "\n",
    "        self.patch_embed = nn.Conv2d(\n",
    "            in_channels, embed_dim, kernel_size=patch_size, stride=patch_size\n",
    "        )\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, self.num_patches + 1, embed_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)                     # (B, D, H/P, W/P)\n",
    "        x = x.flatten(2).transpose(1, 2)            # (B, N, D)\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)  # (B, 1, D)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)       # (B, N+1, D) Concatinate CLS token at the beginning\n",
    "        x = x + self.pos_embed                      # Positional encoding\n",
    "        return x # (B, N+1, D)\n"
   ],
   "metadata": {
    "id": "Q1W3SfrPKH8D",
    "ExecuteTime": {
     "end_time": "2025-10-04T12:16:35.370560Z",
     "start_time": "2025-10-04T12:16:35.356920Z"
    }
   },
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim=EMBED_DIM, num_heads=HEADS_NUM):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        assert (\n",
    "            self.head_dim * num_heads == embed_dim\n",
    "        ), \"embed_dim must be divisible by num_heads\"\n",
    "\n",
    "        self.qkv_proj = nn.Linear(embed_dim, embed_dim * 3)\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x, return_attention=False): # takes in embeddings of shpape (B, N + 1, D)\n",
    "        B, N, D = x.shape # (B, N+1, D)\n",
    "        qkv = self.qkv_proj(x)                                     # (B, N+1, 3*D)\n",
    "        qkv = qkv.reshape(B, N, 3, self.num_heads, self.head_dim)  # (B, N+1, 3, H, D/H)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)                           # (3, B, H, N+1, D/H)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]                           # Split Q, K, V\n",
    "\n",
    "        attn_scores = torch.einsum(\"bhnd,bhmd->bhnm\", q / (self.head_dim ** 0.5), k) # (B, H, N+1, N+1)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1) # (B, H, N+1, N+1)\n",
    "        attn_output = torch.einsum(\"bhnm,bhmd->bhnd\", attn_weights, v) # (B, H, N+1, D/H)\n",
    "        attn_output = attn_output.transpose(1, 2).reshape(B, N, D)  # (B, H, N+1, D/H) --> (B, N+1, H, D/H) --> (B, N+1, D)\n",
    "\n",
    "        if return_attention:\n",
    "            return self.out_proj(attn_output), attn_weights\n",
    "\n",
    "        return self.out_proj(attn_output)"
   ],
   "metadata": {
    "id": "gelMOAlHLsDi",
    "ExecuteTime": {
     "end_time": "2025-10-04T12:16:35.665282Z",
     "start_time": "2025-10-04T12:16:35.656451Z"
    }
   },
   "outputs": [],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim=EMBED_DIM):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_dim) # Normalization layer for MSA\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(embed_dim) # Normalization layer for MLP\n",
    "\n",
    "        self.MSA = MultiHeadAttention(embed_dim=embed_dim)\n",
    "\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim, embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.MSA(self.norm1(x))   # (B, N+1, D)\n",
    "        x = x + self.MLP(self.norm2(x))   # (B, N+1, D)\n",
    "        return x"
   ],
   "metadata": {
    "id": "AchNfO4_L38G",
    "ExecuteTime": {
     "end_time": "2025-10-04T12:16:35.969354Z",
     "start_time": "2025-10-04T12:16:35.961668Z"
    }
   },
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "source": [
    "class ViTTransformers(nn.Module):\n",
    "    def __init__(self, num_classes=10,\n",
    "                 block_num=BLOCK_SIZE,\n",
    "                 img_size=IMAGE_SIZE,\n",
    "                 patch_size=PATCH_SIZE,\n",
    "                 in_channels=3,\n",
    "                 embed_dim=EMBED_DIM):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = ViTEmbedding(img_size,\n",
    "                                      patch_size,\n",
    "                                      in_channels,\n",
    "                                      embed_dim)\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            TransformerEncoder(embed_dim) for _ in range(block_num)\n",
    "        ])\n",
    "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # (B, N+1, D)\n",
    "        for encoder in self.encoder_layers:\n",
    "            x = encoder(x)\n",
    "        cls_token = x[:, 0]  # Extract CLS token\n",
    "        return self.classifier(cls_token)  # (B, num_classes)"
   ],
   "metadata": {
    "id": "s7AtMLGfMDjG",
    "ExecuteTime": {
     "end_time": "2025-10-04T12:16:36.724232Z",
     "start_time": "2025-10-04T12:16:36.717580Z"
    }
   },
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_0 = ViTTransformers().to(device)\n",
    "test_input = torch.randn(BATCH_SIZE, 3, IMAGE_SIZE, IMAGE_SIZE).to(device)  # Batch size of 32\n",
    "output = model_0(test_input)\n",
    "print(device)\n",
    "print(f\"Output shape: {output.shape}\")  # Should be (32, 10) for CIFAR-10"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OfqKEtWNMVPq",
    "outputId": "b7265984-1aca-4ce5-9990-cd616dcfb16a",
    "ExecuteTime": {
     "end_time": "2025-10-04T12:16:37.231296Z",
     "start_time": "2025-10-04T12:16:37.087617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Output shape: torch.Size([128, 10])\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "source": [
    "# from torch.optim.lr_scheduler import MultiStepLR\n",
    "# scheduler = MultiStepLR(optimizer, milestones=[10*i for i in range(1,3)], gamma=0.5)"
   ],
   "metadata": {
    "id": "_eZX0fKGXGzk",
    "ExecuteTime": {
     "end_time": "2025-10-04T12:16:37.966965Z",
     "start_time": "2025-10-04T12:16:37.962114Z"
    }
   },
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "52291df3",
    "ExecuteTime": {
     "end_time": "2025-10-04T11:55:38.323646Z",
     "start_time": "2025-10-04T11:55:34.469636Z"
    }
   },
   "source": [
    "!pip install torchinfo -q"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T12:16:41.297187Z",
     "start_time": "2025-10-04T12:16:41.260414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model=model_0,\n",
    "        input_size=(BATCH_SIZE, 3, IMAGE_SIZE, IMAGE_SIZE),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "ViTTransformers (ViTTransformers)        [128, 3, 32, 32]     [128, 10]            --                   True\n",
       "├─ViTEmbedding (embedding)               [128, 3, 32, 32]     [128, 65, 256]       16,896               True\n",
       "│    └─Conv2d (patch_embed)              [128, 3, 32, 32]     [128, 256, 8, 8]     12,544               True\n",
       "├─ModuleList (encoder_layers)            --                   --                   --                   True\n",
       "│    └─TransformerEncoder (0)            [128, 65, 256]       [128, 65, 256]       --                   True\n",
       "│    │    └─LayerNorm (norm1)            [128, 65, 256]       [128, 65, 256]       512                  True\n",
       "│    │    └─MultiHeadAttention (MSA)     [128, 65, 256]       [128, 65, 256]       263,168              True\n",
       "│    │    └─LayerNorm (norm2)            [128, 65, 256]       [128, 65, 256]       512                  True\n",
       "│    │    └─Sequential (MLP)             [128, 65, 256]       [128, 65, 256]       131,584              True\n",
       "│    └─TransformerEncoder (1)            [128, 65, 256]       [128, 65, 256]       --                   True\n",
       "│    │    └─LayerNorm (norm1)            [128, 65, 256]       [128, 65, 256]       512                  True\n",
       "│    │    └─MultiHeadAttention (MSA)     [128, 65, 256]       [128, 65, 256]       263,168              True\n",
       "│    │    └─LayerNorm (norm2)            [128, 65, 256]       [128, 65, 256]       512                  True\n",
       "│    │    └─Sequential (MLP)             [128, 65, 256]       [128, 65, 256]       131,584              True\n",
       "│    └─TransformerEncoder (2)            [128, 65, 256]       [128, 65, 256]       --                   True\n",
       "│    │    └─LayerNorm (norm1)            [128, 65, 256]       [128, 65, 256]       512                  True\n",
       "│    │    └─MultiHeadAttention (MSA)     [128, 65, 256]       [128, 65, 256]       263,168              True\n",
       "│    │    └─LayerNorm (norm2)            [128, 65, 256]       [128, 65, 256]       512                  True\n",
       "│    │    └─Sequential (MLP)             [128, 65, 256]       [128, 65, 256]       131,584              True\n",
       "│    └─TransformerEncoder (3)            [128, 65, 256]       [128, 65, 256]       --                   True\n",
       "│    │    └─LayerNorm (norm1)            [128, 65, 256]       [128, 65, 256]       512                  True\n",
       "│    │    └─MultiHeadAttention (MSA)     [128, 65, 256]       [128, 65, 256]       263,168              True\n",
       "│    │    └─LayerNorm (norm2)            [128, 65, 256]       [128, 65, 256]       512                  True\n",
       "│    │    └─Sequential (MLP)             [128, 65, 256]       [128, 65, 256]       131,584              True\n",
       "│    └─TransformerEncoder (4)            [128, 65, 256]       [128, 65, 256]       --                   True\n",
       "│    │    └─LayerNorm (norm1)            [128, 65, 256]       [128, 65, 256]       512                  True\n",
       "│    │    └─MultiHeadAttention (MSA)     [128, 65, 256]       [128, 65, 256]       263,168              True\n",
       "│    │    └─LayerNorm (norm2)            [128, 65, 256]       [128, 65, 256]       512                  True\n",
       "│    │    └─Sequential (MLP)             [128, 65, 256]       [128, 65, 256]       131,584              True\n",
       "│    └─TransformerEncoder (5)            [128, 65, 256]       [128, 65, 256]       --                   True\n",
       "│    │    └─LayerNorm (norm1)            [128, 65, 256]       [128, 65, 256]       512                  True\n",
       "│    │    └─MultiHeadAttention (MSA)     [128, 65, 256]       [128, 65, 256]       263,168              True\n",
       "│    │    └─LayerNorm (norm2)            [128, 65, 256]       [128, 65, 256]       512                  True\n",
       "│    │    └─Sequential (MLP)             [128, 65, 256]       [128, 65, 256]       131,584              True\n",
       "│    └─TransformerEncoder (6)            [128, 65, 256]       [128, 65, 256]       --                   True\n",
       "│    │    └─LayerNorm (norm1)            [128, 65, 256]       [128, 65, 256]       512                  True\n",
       "│    │    └─MultiHeadAttention (MSA)     [128, 65, 256]       [128, 65, 256]       263,168              True\n",
       "│    │    └─LayerNorm (norm2)            [128, 65, 256]       [128, 65, 256]       512                  True\n",
       "│    │    └─Sequential (MLP)             [128, 65, 256]       [128, 65, 256]       131,584              True\n",
       "│    └─TransformerEncoder (7)            [128, 65, 256]       [128, 65, 256]       --                   True\n",
       "│    │    └─LayerNorm (norm1)            [128, 65, 256]       [128, 65, 256]       512                  True\n",
       "│    │    └─MultiHeadAttention (MSA)     [128, 65, 256]       [128, 65, 256]       263,168              True\n",
       "│    │    └─LayerNorm (norm2)            [128, 65, 256]       [128, 65, 256]       512                  True\n",
       "│    │    └─Sequential (MLP)             [128, 65, 256]       [128, 65, 256]       131,584              True\n",
       "├─Linear (classifier)                    [128, 256]           [128, 10]            2,570                True\n",
       "========================================================================================================================\n",
       "Total params: 3,198,218\n",
       "Trainable params: 3,198,218\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 508.36\n",
       "========================================================================================================================\n",
       "Input size (MB): 1.57\n",
       "Forward/backward pass size (MB): 1107.31\n",
       "Params size (MB): 12.73\n",
       "Estimated Total Size (MB): 1121.60\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model_0.parameters(), lr=5e-2, weight_decay=0.05)\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "warmup_steps = int(0.25 * total_steps)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
    ")\n",
    "print(warmup_steps) #2346"
   ],
   "metadata": {
    "id": "YsNH3DiTQDlh",
    "ExecuteTime": {
     "end_time": "2025-10-04T12:40:03.433863Z",
     "start_time": "2025-10-04T12:40:03.407301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7820\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_dataloader, test_dataloader, loss_fn, optimizer, epochs, device, scheduler=None, use_wandb=True):\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    run = wandb.init(\n",
    "        entity=\"hellcasterz-nit-warangal\",\n",
    "        # Set the wandb project where this run will be logged.\n",
    "        project=\"Vision_Transformer\",\n",
    "        # Track hyperparameters and run metadata.\n",
    "        config={\n",
    "            \"learning_rate\": optimizer.param_groups[0][\"lr\"],\n",
    "            \"architecture\": \"ViT\",\n",
    "            \"dataset\": \"CIFAR-100\",\n",
    "            \"epochs\": epochs,\n",
    "        },\n",
    "    )\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, train_correct, total = 0, 0, 0\n",
    "\n",
    "        loop = tqdm(train_dataloader, leave=False, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for X, y in loop:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            preds = model(X)\n",
    "            loss = loss_fn(preds, y)\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * X.size(0)\n",
    "            _, predicted = preds.max(1)\n",
    "            train_correct += predicted.eq(y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_train_loss = train_loss / total\n",
    "        avg_train_acc = train_correct / total\n",
    "\n",
    "        model.eval()\n",
    "        test_loss, test_correct, test_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                preds = model(X)\n",
    "                loss = loss_fn(preds, y)\n",
    "\n",
    "                test_loss += loss.item() * X.size(0)\n",
    "                _, predicted = preds.max(1)\n",
    "                test_correct += predicted.eq(y).sum().item()\n",
    "                test_total += y.size(0)\n",
    "\n",
    "        avg_test_loss = test_loss / test_total\n",
    "        avg_test_acc = test_correct / test_total\n",
    "\n",
    "        results[\"train_loss\"].append(avg_train_loss)\n",
    "        results[\"train_acc\"].append(avg_train_acc)\n",
    "        results[\"test_loss\"].append(avg_test_loss)\n",
    "        results[\"test_acc\"].append(avg_test_acc)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "            f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f} \"\n",
    "            f\"Test Loss: {avg_test_loss:.4f}, Test Acc: {avg_test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        if use_wandb:\n",
    "            run.log({\n",
    "                \"Train Loss\": avg_train_loss,\n",
    "                \"Train Acc\": avg_train_acc,\n",
    "                \"Test Loss\": avg_test_loss,\n",
    "                \"Test Acc\": avg_test_acc,\n",
    "                \"Learning Rate\": optimizer.param_groups[0][\"lr\"],\n",
    "            })\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "    if use_wandb:\n",
    "        print(run.summary())\n",
    "        run.finish()\n",
    "    return results\n"
   ],
   "metadata": {
    "id": "gbZmzwfUS9Dd",
    "ExecuteTime": {
     "end_time": "2025-10-04T12:40:05.330513Z",
     "start_time": "2025-10-04T12:40:05.312104Z"
    }
   },
   "outputs": [],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "wandb.login()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "m0JfzfbyTCxl",
    "outputId": "253cc262-84c0-4791-9ea0-b21147b39aca",
    "ExecuteTime": {
     "end_time": "2025-10-04T12:40:11.203056Z",
     "start_time": "2025-10-04T12:40:09.782851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (0.22.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click>=8.0.1 in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from wandb) (8.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from wandb) (3.1.45)\n",
      "Requirement already satisfied: packaging in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: platformdirs in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from wandb) (4.3.8)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from wandb) (6.32.1)\n",
      "Requirement already satisfied: pydantic<3 in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from wandb) (2.11.9)\n",
      "Requirement already satisfied: pyyaml in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from wandb) (2.32.4)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from wandb) (2.39.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from wandb) (4.14.1)\n",
      "Requirement already satisfied: colorama in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from click>=8.0.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from pydantic<3->wandb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from pydantic<3->wandb) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.6.15)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in d:\\anacodes\\pythonproject2\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "source": [
    "results =train(model=model_0,\n",
    "      train_dataloader=train_dataloader,\n",
    "      test_dataloader=test_dataloader,\n",
    "      loss_fn=loss_fn,\n",
    "      optimizer=optimizer,\n",
    "      epochs=EPOCHS,\n",
    "      device=device,\n",
    "      scheduler=scheduler\n",
    "      )  # Reduced epochs for quicker testing"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 931
    },
    "id": "rDygLWXWQrLj",
    "outputId": "e953c262-c11e-42d9-8e64-ba1f72ef40df",
    "ExecuteTime": {
     "end_time": "2025-10-04T17:58:16.099404Z",
     "start_time": "2025-10-04T12:40:13.596569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▄▅▇█</td></tr><tr><td>Learning Rate</td><td>▁▂▄▅▇█</td></tr><tr><td>Test Acc</td><td>▁▄▅▆██</td></tr><tr><td>Test Loss</td><td>█▄▃▃▁▁</td></tr><tr><td>Train Acc</td><td>▁▁▄▆▇█</td></tr><tr><td>Train Loss</td><td>█▅▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>6</td></tr><tr><td>Learning Rate</td><td>0.0</td></tr><tr><td>Test Acc</td><td>0.2185</td></tr><tr><td>Test Loss</td><td>2.08379</td></tr><tr><td>Train Acc</td><td>0.2206</td></tr><tr><td>Train Loss</td><td>2.10803</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vital-disco-8</strong> at: <a href='https://wandb.ai/hellcasterz-nit-warangal/Vision_Transformer/runs/pk9ox2xg' target=\"_blank\">https://wandb.ai/hellcasterz-nit-warangal/Vision_Transformer/runs/pk9ox2xg</a><br> View project at: <a href='https://wandb.ai/hellcasterz-nit-warangal/Vision_Transformer' target=\"_blank\">https://wandb.ai/hellcasterz-nit-warangal/Vision_Transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251004_174644-pk9ox2xg\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>D:\\ANAcodes\\PythonProject2\\wandb\\run-20251004_181013-kbvhrp27</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hellcasterz-nit-warangal/Vision_Transformer/runs/kbvhrp27' target=\"_blank\">clear-energy-9</a></strong> to <a href='https://wandb.ai/hellcasterz-nit-warangal/Vision_Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/hellcasterz-nit-warangal/Vision_Transformer' target=\"_blank\">https://wandb.ai/hellcasterz-nit-warangal/Vision_Transformer</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/hellcasterz-nit-warangal/Vision_Transformer/runs/kbvhrp27' target=\"_blank\">https://wandb.ai/hellcasterz-nit-warangal/Vision_Transformer/runs/kbvhrp27</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/80] Train Loss: 2.0927, Train Acc: 0.2230 Test Loss: 2.0793, Test Acc: 0.2416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/80] Train Loss: 2.0767, Train Acc: 0.2333 Test Loss: 2.0315, Test Acc: 0.2434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/80] Train Loss: 2.0142, Train Acc: 0.2582 Test Loss: 1.9751, Test Acc: 0.2832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/80] Train Loss: 1.9667, Train Acc: 0.2779 Test Loss: 1.9013, Test Acc: 0.3086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/80] Train Loss: 1.9314, Train Acc: 0.2939 Test Loss: 1.8594, Test Acc: 0.3309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/80] Train Loss: 1.8816, Train Acc: 0.3129 Test Loss: 1.7451, Test Acc: 0.3699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/80] Train Loss: 1.8158, Train Acc: 0.3378 Test Loss: 1.6878, Test Acc: 0.3893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/80] Train Loss: 1.7570, Train Acc: 0.3562 Test Loss: 1.6124, Test Acc: 0.4152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/80] Train Loss: 1.7008, Train Acc: 0.3803 Test Loss: 1.5320, Test Acc: 0.4508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/80] Train Loss: 1.6599, Train Acc: 0.3960 Test Loss: 1.5304, Test Acc: 0.4461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/80] Train Loss: 1.6267, Train Acc: 0.4086 Test Loss: 1.4520, Test Acc: 0.4764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/80] Train Loss: 1.5871, Train Acc: 0.4237 Test Loss: 1.4116, Test Acc: 0.4943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/80] Train Loss: 1.5609, Train Acc: 0.4363 Test Loss: 1.3890, Test Acc: 0.5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/80] Train Loss: 1.5332, Train Acc: 0.4433 Test Loss: 1.3700, Test Acc: 0.5085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/80] Train Loss: 1.5002, Train Acc: 0.4562 Test Loss: 1.3478, Test Acc: 0.5236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/80] Train Loss: 1.4790, Train Acc: 0.4655 Test Loss: 1.2957, Test Acc: 0.5321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/80] Train Loss: 1.4522, Train Acc: 0.4769 Test Loss: 1.3082, Test Acc: 0.5248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/80] Train Loss: 1.4225, Train Acc: 0.4853 Test Loss: 1.2580, Test Acc: 0.5448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/80] Train Loss: 1.4005, Train Acc: 0.4960 Test Loss: 1.2399, Test Acc: 0.5572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/80] Train Loss: 1.3751, Train Acc: 0.5034 Test Loss: 1.2255, Test Acc: 0.5559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/80] Train Loss: 1.3524, Train Acc: 0.5138 Test Loss: 1.1992, Test Acc: 0.5690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/80] Train Loss: 1.3315, Train Acc: 0.5210 Test Loss: 1.2313, Test Acc: 0.5550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/80] Train Loss: 1.3168, Train Acc: 0.5258 Test Loss: 1.2099, Test Acc: 0.5593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/80] Train Loss: 1.2967, Train Acc: 0.5336 Test Loss: 1.1687, Test Acc: 0.5783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/80] Train Loss: 1.2781, Train Acc: 0.5393 Test Loss: 1.1502, Test Acc: 0.5852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/80] Train Loss: 1.2588, Train Acc: 0.5502 Test Loss: 1.1257, Test Acc: 0.5947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/80] Train Loss: 1.2461, Train Acc: 0.5530 Test Loss: 1.1244, Test Acc: 0.5932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/80] Train Loss: 1.2220, Train Acc: 0.5617 Test Loss: 1.0931, Test Acc: 0.6039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/80] Train Loss: 1.2027, Train Acc: 0.5696 Test Loss: 1.0811, Test Acc: 0.6105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/80] Train Loss: 1.1918, Train Acc: 0.5714 Test Loss: 1.0608, Test Acc: 0.6206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/80] Train Loss: 1.1745, Train Acc: 0.5769 Test Loss: 1.0401, Test Acc: 0.6246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/80] Train Loss: 1.1591, Train Acc: 0.5860 Test Loss: 1.0551, Test Acc: 0.6194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/80] Train Loss: 1.1399, Train Acc: 0.5941 Test Loss: 1.0272, Test Acc: 0.6328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/80] Train Loss: 1.1205, Train Acc: 0.5983 Test Loss: 1.0321, Test Acc: 0.6271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/80] Train Loss: 1.1085, Train Acc: 0.6037 Test Loss: 0.9857, Test Acc: 0.6441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/80] Train Loss: 1.0939, Train Acc: 0.6105 Test Loss: 0.9915, Test Acc: 0.6462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/80] Train Loss: 1.0760, Train Acc: 0.6155 Test Loss: 0.9619, Test Acc: 0.6588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/80] Train Loss: 1.0696, Train Acc: 0.6164 Test Loss: 0.9720, Test Acc: 0.6565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/80] Train Loss: 1.0528, Train Acc: 0.6242 Test Loss: 0.9753, Test Acc: 0.6545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/80] Train Loss: 1.0388, Train Acc: 0.6294 Test Loss: 0.9354, Test Acc: 0.6680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/80] Train Loss: 1.0197, Train Acc: 0.6356 Test Loss: 0.9475, Test Acc: 0.6577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/80] Train Loss: 1.0114, Train Acc: 0.6385 Test Loss: 0.9129, Test Acc: 0.6718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/80] Train Loss: 0.9957, Train Acc: 0.6432 Test Loss: 0.9394, Test Acc: 0.6714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/80] Train Loss: 0.9871, Train Acc: 0.6464 Test Loss: 0.9410, Test Acc: 0.6639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/80] Train Loss: 0.9704, Train Acc: 0.6537 Test Loss: 0.9289, Test Acc: 0.6686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/80] Train Loss: 0.9680, Train Acc: 0.6568 Test Loss: 0.9188, Test Acc: 0.6720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/80] Train Loss: 0.9492, Train Acc: 0.6604 Test Loss: 0.8890, Test Acc: 0.6860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/80] Train Loss: 0.9335, Train Acc: 0.6672 Test Loss: 0.9080, Test Acc: 0.6828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/80] Train Loss: 0.9218, Train Acc: 0.6721 Test Loss: 0.8801, Test Acc: 0.6873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/80] Train Loss: 0.9164, Train Acc: 0.6745 Test Loss: 0.8548, Test Acc: 0.6933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/80] Train Loss: 0.8970, Train Acc: 0.6775 Test Loss: 0.8605, Test Acc: 0.6967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/80] Train Loss: 0.8917, Train Acc: 0.6832 Test Loss: 0.8750, Test Acc: 0.6967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/80] Train Loss: 0.8798, Train Acc: 0.6863 Test Loss: 0.8323, Test Acc: 0.6999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/80] Train Loss: 0.8733, Train Acc: 0.6873 Test Loss: 0.8162, Test Acc: 0.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/80] Train Loss: 0.8629, Train Acc: 0.6942 Test Loss: 0.8079, Test Acc: 0.7138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/80] Train Loss: 0.8493, Train Acc: 0.6993 Test Loss: 0.8201, Test Acc: 0.7129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/80] Train Loss: 0.8418, Train Acc: 0.6958 Test Loss: 0.8434, Test Acc: 0.7071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/80] Train Loss: 0.8302, Train Acc: 0.7047 Test Loss: 0.8362, Test Acc: 0.7099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/80] Train Loss: 0.8179, Train Acc: 0.7063 Test Loss: 0.8481, Test Acc: 0.7022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/80] Train Loss: 0.8124, Train Acc: 0.7094 Test Loss: 0.8358, Test Acc: 0.7103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/80] Train Loss: 0.8044, Train Acc: 0.7138 Test Loss: 0.7860, Test Acc: 0.7271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/80] Train Loss: 0.7887, Train Acc: 0.7206 Test Loss: 0.8302, Test Acc: 0.7088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/80] Train Loss: 0.7828, Train Acc: 0.7193 Test Loss: 0.7627, Test Acc: 0.7342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/80] Train Loss: 0.7703, Train Acc: 0.7263 Test Loss: 0.7889, Test Acc: 0.7216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/80] Train Loss: 0.7590, Train Acc: 0.7301 Test Loss: 0.7641, Test Acc: 0.7302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/80] Train Loss: 0.7529, Train Acc: 0.7321 Test Loss: 0.7568, Test Acc: 0.7335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/80] Train Loss: 0.7432, Train Acc: 0.7351 Test Loss: 0.7956, Test Acc: 0.7240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/80] Train Loss: 0.7327, Train Acc: 0.7380 Test Loss: 0.7640, Test Acc: 0.7359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/80] Train Loss: 0.7249, Train Acc: 0.7430 Test Loss: 0.7576, Test Acc: 0.7373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/80] Train Loss: 0.7234, Train Acc: 0.7399 Test Loss: 0.7564, Test Acc: 0.7394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/80] Train Loss: 0.7158, Train Acc: 0.7438 Test Loss: 0.7773, Test Acc: 0.7272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/80] Train Loss: 0.7029, Train Acc: 0.7478 Test Loss: 0.7298, Test Acc: 0.7456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/80] Train Loss: 0.6967, Train Acc: 0.7515 Test Loss: 0.7704, Test Acc: 0.7347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/80] Train Loss: 0.6840, Train Acc: 0.7547 Test Loss: 0.7605, Test Acc: 0.7338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/80] Train Loss: 0.6746, Train Acc: 0.7604 Test Loss: 0.7661, Test Acc: 0.7344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/80] Train Loss: 0.6709, Train Acc: 0.7607 Test Loss: 0.7423, Test Acc: 0.7442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/80] Train Loss: 0.6659, Train Acc: 0.7627 Test Loss: 0.7303, Test Acc: 0.7475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/80] Train Loss: 0.6543, Train Acc: 0.7657 Test Loss: 0.7442, Test Acc: 0.7427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/80] Train Loss: 0.6423, Train Acc: 0.7699 Test Loss: 0.7553, Test Acc: 0.7419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/80] Train Loss: 0.6421, Train Acc: 0.7729 Test Loss: 0.7330, Test Acc: 0.7500\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Summary' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[77]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m results =\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m      \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m      \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m      \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m=\u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m      \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m=\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m      \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m      \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m      \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m=\u001B[49m\u001B[43mscheduler\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m      \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Reduced epochs for quicker testing\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[75]\u001B[39m\u001B[32m, line 89\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m(model, train_dataloader, test_dataloader, loss_fn, optimizer, epochs, device, scheduler, use_wandb)\u001B[39m\n\u001B[32m     87\u001B[39m         scheduler.step()\n\u001B[32m     88\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m use_wandb:\n\u001B[32m---> \u001B[39m\u001B[32m89\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[43mrun\u001B[49m\u001B[43m.\u001B[49m\u001B[43msummary\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     90\u001B[39m     run.finish()\n\u001B[32m     91\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m results\n",
      "\u001B[31mTypeError\u001B[39m: 'Summary' object is not callable"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Upm_HhVtQwwL"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
